{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15ea904",
   "metadata": {},
   "source": [
    "# Aperiodic electrophysiological activity tracks spiking statistics between behavioral states\n",
    "Sawyer Figueroa, Michael Preston, Bradley Voytek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c809624",
   "metadata": {},
   "source": [
    "# SfN 2023, Poster Panel 4\n",
    "This notebook reproduces the figures from poster panel 4. Panel 4 investigates the relationship between spike-synchrony and aperiodic LFP activity. Comparisons are made between behavioral epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70791ac1",
   "metadata": {},
   "source": [
    "Dataset: Allen Institute for Brain Science: Visual Coding - Neuropixels  \n",
    "Â© 2015 Allen Institute for Brain Science. Allen Brain Atlas API. Available from: https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf1119",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a6c08",
   "metadata": {},
   "source": [
    "### set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3dacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "PROJECT_PATH = \"G:/Shared drives/visual_encoding\" # shared results directory\n",
    "MANIFEST_PATH = 'D:/datasets/allen_vc' # path to manifest file and local dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4814c",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as sts\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15acbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from allen_vc.plots import scatter_2_conditions\n",
    "from allen_vc.utils import combine_spike_lfp_dfs, channel_medians\n",
    "\n",
    "print(\"Imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a3ca6",
   "metadata": {},
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib and figure appearance settings\n",
    "plt.style.use(f'../../stylelib/sfn_2023.mplstyle')\n",
    "# COLORS = [\"#7570b3\", \"#3FAA96\", \"#F39943\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f81986",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29198e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for stim: natural_movie_one_more_repeats\n",
    "\n",
    "# load spike data\n",
    "movie_spikes = pd.read_csv(f'{PROJECT_PATH}/data/spike_stats/natural_movie_one_more_repeats.csv')\n",
    "\n",
    "# load lfp data\n",
    "# movie_lfp = pd.read_csv(f'{PROJECT_PATH}/data/lfp_data/pavrams/psd/natural_movie_one_more_repeats/lfp_params.csv')\n",
    "\n",
    "# load lfp data - join params across sessions ! TEMP !\n",
    "# this is a temporary fix: this should be performed by the analysis script\n",
    "path_in = f'{PROJECT_PATH}/data/lfp_data/params/psd/natural_movie_one_more_repeats/by_session'\n",
    "files = os.listdir(path_in)\n",
    "df_list = []\n",
    "for fname in files:\n",
    "    df_list.append(pd.read_csv(f'{path_in}/{fname}'))\n",
    "movie_lfp = pd.concat(df_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for stim: natural_movie_one_shuffled\n",
    "\n",
    "# load spike data\n",
    "shuffled_spikes = pd.read_csv(f'{PROJECT_PATH}/data/spike_stats/natural_movie_one_shuffled.csv')\n",
    "\n",
    "# load lfp data\n",
    "# shuffled_lfp = pd.read_csv(f'{PROJECT_PATH}/data/lfp_data/params/psd/natural_movie_one_shuffled/lfp_params.csv')\n",
    "\n",
    "# load lfp data - join params across sessions ! TEMP !\n",
    "# this is a temporary fix: this should be performed by the analysis script\n",
    "path_in = f'{PROJECT_PATH}/data/lfp_data/params/psd/natural_movie_one_shuffled/by_session'\n",
    "files = os.listdir(path_in)\n",
    "df_list = []\n",
    "for fname in files:\n",
    "    df_list.append(pd.read_csv(f'{path_in}/{fname}'))\n",
    "shuffled_lfp = pd.concat(df_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a87aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88801a39",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b1125",
   "metadata": {},
   "source": [
    "#### All session mean firing rate vs. broadband offset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98f7e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop through stimuli\n",
    "for stimulus, df_lfp, df_units in zip(['movie', 'shuffled'], \n",
    "                                      [movie_lfp, shuffled_lfp],\n",
    "                                      [movie_spikes, shuffled_spikes]):\n",
    "    # modify df_lfp - average over channels for each epoch within each session\n",
    "    df_lfp_i = df_lfp.groupby(['session', 'epoch_idx']).mean().reset_index()\n",
    "\n",
    "    # loop through spiking region\n",
    "    for spike_region in ['VISp', 'LGd']:\n",
    "        # get unit data for this region\n",
    "        df_units_i = df_units[df_units.get(\"brain_structure\")==spike_region]  \n",
    "\n",
    "        # merge unit and lfp dataframes\n",
    "        df_i = df_lfp_i.merge(df_units_i, on=['session', 'epoch_idx'])\n",
    "\n",
    "        # loop through behavioral conditions\n",
    "        for behavior, running in zip(['running', 'stationary'], [True, False]):\n",
    "\n",
    "            # filter df by behavior\n",
    "            df = df_i[df_i.get('running')==running]\n",
    "            \n",
    "            # plot each session\n",
    "            sessions = df.get('session').unique()\n",
    "            fig, ax = plt.subplots(figsize=(8,6), constrained_layout=True)\n",
    "            fig.patch.set_facecolor('white')\n",
    "            for ses in sessions:\n",
    "                ses_df = df[df.get('session')==ses]\n",
    "\n",
    "                # plot each epoch\n",
    "                sc =  ax.scatter(ses_df.get('mean_firing_rate'), \n",
    "                                 ses_df.get('offset'), label=ses)\n",
    "\n",
    "                # plot session mean\n",
    "                ax.scatter(ses_df.get('mean_firing_rate').mean(), \n",
    "                           ses_df.get('offset').mean(), color=sc.get_facecolors()[0], s=100)\n",
    "                sc.set_alpha(0.5)\n",
    "                \n",
    "            # run regression across all epochs and plot results\n",
    "            df_avg = df.groupby(['session']).mean().reset_index()# average across trials\n",
    "            x_data = df_avg.get('mean_firing_rate')\n",
    "            y_data = df_avg.get('offset')\n",
    "            results = sts.linregress(x_data, y_data)\n",
    "            l1 = np.linspace(min(x_data), max(x_data), 1000)\n",
    "            t1 = results.slope * l1 + results.intercept\n",
    "            ax.plot(l1, t1, color='k', linewidth=3)\n",
    "\n",
    "            # add regression results text\n",
    "            if results.pvalue < 0.001:\n",
    "                pval = f\"{results.pvalue:.2e}\"\n",
    "            else:\n",
    "                pval = f\"{results.pvalue:.3f}\"\n",
    "            plt.text(1.05, 0.9, \n",
    "                    f\"Linear regression:\\n\" +\n",
    "                    f\"    Slope: {results.slope:.3f}\\n\" +\n",
    "                    f\"    Intercept: {results.intercept:.3f}\\n\" +\n",
    "                    f\"    R: {results.rvalue:.3f}\\n\" +\n",
    "                    f\"    p: {pval}\", transform = ax.transAxes)\n",
    "\n",
    "            # label\n",
    "            ax.legend(bbox_to_anchor=(1.05, -.1), loc='lower left', borderaxespad=0.)\n",
    "            plt.xlabel(\"mean firing rate (Hz)\")\n",
    "            plt.ylabel(\"broadband offset\")\n",
    "            plt.title(f\"{stimulus} - {behavior} \\n({spike_region} unit activtiy)\")\n",
    "            \n",
    "            # save\n",
    "            dir_figures = f\"{PROJECT_PATH}/figures/offset_vs_rate/{spike_region}/{behavior}\"\n",
    "            # plt.savefig(f\"{dir_figures}/all_sessions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0eb14",
   "metadata": {},
   "source": [
    "#### All session SPIKE-distance vs. LFP exponent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through stimuli\n",
    "for stimulus, df_lfp, df_units in zip(['movie', 'shuffled'], \n",
    "                                      [movie_lfp, shuffled_lfp],\n",
    "                                      [movie_spikes, shuffled_spikes]):\n",
    "    # modify df_lfp - average over channels for each epoch within each session\n",
    "    df_lfp_i = df_lfp.groupby(['session', 'epoch_idx']).mean().reset_index()\n",
    "\n",
    "    # loop through spiking region\n",
    "    for spike_region in ['VISp', 'LGd']:\n",
    "        # get unit data for this region\n",
    "        df_units_i = df_units[df_units.get(\"brain_structure\")==spike_region]  \n",
    "\n",
    "        # merge unit and lfp dataframes\n",
    "        df_i = df_lfp_i.merge(df_units_i, on=['session', 'epoch_idx'])\n",
    "\n",
    "        # loop through behavioral conditions\n",
    "        for behavior, running in zip(['running', 'stationary'], [True, False]):\n",
    "\n",
    "            # filter df by behavior\n",
    "            df = df_i[df_i.get('running')==running]\n",
    "\n",
    "            # create figure\n",
    "            fig, ax = plt.subplots(figsize=(8,6), constrained_layout=True)\n",
    "            fig.patch.set_facecolor('white')\n",
    "\n",
    "            # plot each session\n",
    "            sessions = df.get('session').unique()\n",
    "            for ses in sessions:\n",
    "                ses_df = df[df.get('session')==ses]\n",
    "\n",
    "                # plot each epoch\n",
    "                sc =  ax.scatter(ses_df.get('spike_distance'), \n",
    "                                 ses_df.get('exponent'), label=ses)\n",
    "\n",
    "                # plot session mean\n",
    "                ax.scatter(ses_df.get('spike_distance').mean(), \n",
    "                           ses_df.get('exponent').mean(), color=sc.get_facecolors()[0], s=100)\n",
    "                sc.set_alpha(0.5)\n",
    "                \n",
    "            # run regression across all epochs and plot results\n",
    "            df_avg = df.groupby(['session']).mean().reset_index()# average across trials\n",
    "            x_data = df_avg.get('spike_distance')\n",
    "            y_data = df_avg.get('exponent')\n",
    "            results = sts.linregress(x_data, y_data)\n",
    "            l1 = np.linspace(min(x_data), max(x_data), 1000)\n",
    "            t1 = results.slope * l1 + results.intercept\n",
    "            ax.plot(l1, t1, color='k', linewidth=3)\n",
    "\n",
    "            # add regression results text\n",
    "            if results.pvalue < 0.001:\n",
    "                pval = f\"{results.pvalue:.2e}\"\n",
    "            else:\n",
    "                pval = f\"{results.pvalue:.3f}\"\n",
    "            plt.text(1.05, 0.9, \n",
    "                    f\"Linear regression:\\n\" +\n",
    "                    f\"    Slope: {results.slope:.3f}\\n\" +\n",
    "                    f\"    Intercept: {results.intercept:.3f}\\n\" +\n",
    "                    f\"    R: {results.rvalue:.3f}\\n\" +\n",
    "                    f\"    p: {pval}\", transform = ax.transAxes)\n",
    "\n",
    "            # label\n",
    "            ax.legend(bbox_to_anchor=(1.05, .8), loc='upper left', borderaxespad=0.)\n",
    "            plt.xlabel(\"SPIKE-distance\")\n",
    "            plt.ylabel(\"LFP exponent\")\n",
    "            plt.title(f\"{stimulus} - {behavior} \\n({spike_region} unit activtiy)\")\n",
    "            \n",
    "            # save\n",
    "            dir_figures = f\"{PROJECT_PATH}/figures/exponent_vs_synchrony/{spike_region}/{behavior}\"\n",
    "            # plt.savefig(f\"{dir_figures}/all_sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c29d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3563c43",
   "metadata": {},
   "source": [
    "### regression analysis - Spontaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863cb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at parameter comparisons\n",
    "\n",
    "# spike_sync vs. exponent graph + pearson R\n",
    "# offset vs. firing rate\n",
    "\n",
    "# SPLIT BASED ON BEHAVIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bd9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nans for this session maybe missing lfp data in this last few epochs? (should be 44 below epochs), NOTE: session has nans in lfp\n",
    "\n",
    "# e = params_df[params_df['session']==847657808]['epoch_idx'].unique()\n",
    "# e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop nans\n",
    "# other_sessions = metric_df[(metric_df['session'] != 847657808)]\n",
    "# nan_session = metric_df[(metric_df['session'] == 847657808) & (metric_df['epoch_idx'].isin(e[~np.isnan(e)]))]\n",
    "\n",
    "# metric_df = pd.concat([other_sessions, nan_session])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6adf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get VISp spike data\n",
    "\n",
    "# load spike stats\n",
    "metric_fp = f'{PROJECT_PATH}/data/spike_stats/no_behavior/spontaneous_running.csv'\n",
    "metric_df = pd.read_csv(metric_fp)\n",
    "\n",
    "# # get VISp rows\n",
    "# m = metric_df[metric_df['brain_structure']=='LGd']\n",
    "\n",
    "# # rename running column\n",
    "# m = m.rename(columns={'running':'behavior'})\n",
    "# m\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LFP spectral params\n",
    "params_r = pd.read_csv(f'{PROJECT_PATH}/data/lfp_data/params/psd/spontaneous_running/lfp_params.csv')\n",
    "params_r['behavior'] = 'above'\n",
    "params_s = pd.read_csv(f'{PROJECT_PATH}/data/lfp_data/params/psd/spontaneous_stationary/lfp_params.csv')\n",
    "params_s['behavior'] = 'below'\n",
    "params_df = pd.concat([params_r, params_s], axis=0)\n",
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute median across LFP channels\n",
    "p = params_df.groupby(['session','behavior','epoch_idx']).median().reset_index().drop(columns='chan_idx')\n",
    "p['epoch_idx'] = p['epoch_idx'].apply(int)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge spike and LFP results\n",
    "df = m.merge(p, on=['session','behavior','epoch_idx'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linregress_plot(x, y):\n",
    "    # imports\n",
    "    from scipy.stats import linregress\n",
    "\n",
    "    # remove NaN\n",
    "    nan_items = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    x = x[~nan_items]\n",
    "    y = y[~nan_items]\n",
    "    \n",
    "    # set up plot\n",
    "    fig, ax = plt.subplots(figsize=(16,12), constrained_layout=True)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    # plot data\n",
    "    sns.scatterplot(x=x, y=y)\n",
    "\n",
    "    # run regression and plot results\n",
    "    results = linregress(x, y)\n",
    "    t_lin = np.linspace(np.nanmin(x), np.nanmax(x), 100)\n",
    "    lin = results.slope * t_lin + results.intercept\n",
    "    ax.plot(t_lin, lin, color='r')\n",
    "\n",
    "    # add regression results text\n",
    "    if results.pvalue < 0.001:\n",
    "        pval = f\"{results.pvalue:.2e}\"\n",
    "    else:\n",
    "        pval = f\"{results.pvalue:.3f}\"\n",
    "    plt.text(1.05, 0.9, \n",
    "             f\"Regression:\\n\" +\n",
    "             f\"    Slope: {results.slope:.3f}\\n\" +\n",
    "             f\"    Intercept: {results.intercept:.3f}\\n\" +\n",
    "             f\"    R: {results.rvalue:.3f}\\n\" +\n",
    "             f\"    p: {pval}\", transform = ax.transAxes, fontsize=15)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot offset v rate\n",
    "\n",
    "results = linregress_plot(x=df['mean_firing_rate'], y=df['offset'])\n",
    "plt.xlabel('mean firing rate (spikes/sec)')\n",
    "plt.ylabel('broadband offset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa249f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot exponent v synchrony\n",
    "\n",
    "results = linregress_plot(x=df['spike_distance'], y=df['exponent'])\n",
    "plt.xlabel('SPIKE-distance')\n",
    "plt.ylabel('LFP exponent');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb89670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove outliers and plot\n",
    "# no_outlier_df = df[df['spike_distance'] > 0.25]\n",
    "\n",
    "# linregressplot(x=no_outlier_df['spike_distance'], y=no_outlier_df['exponent'])\n",
    "# plt.xlabel('SPIKE-distance')\n",
    "# plt.ylabel('LFP exponent');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94383269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for running epochs only\n",
    "behav_df = df.loc[df['behavior'] == 'above']\n",
    "\n",
    "results = linregress_plot(x=behav_df['spike_distance'], y=behav_df['exponent'])\n",
    "plt.xlabel('SPIKE-distance')\n",
    "plt.ylabel('LFP exponent')\n",
    "plt.title('Running');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3874d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for stationary epochs only\n",
    "\n",
    "behav_df = df[df['behavior'] == 'below']\n",
    "\n",
    "results = linregress_plot(x=behav_df['spike_distance'], y=behav_df['exponent'])\n",
    "plt.xlabel('SPIKE-distance')\n",
    "plt.ylabel('LFP exponent')\n",
    "plt.title('Stationary');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
